# 🧪 Mini ETL Project: Credit Risk Dataset (CSV → MySQL)

This mini project demonstrates a simple and clean **ETL pipeline** that reads a credit risk CSV file,transforms it using **Pandas**, and loads it into a **MySQL database**.

This is part of a larger data engineering pipeline where **streaming (Kafka, Debezium)** and **PySpark-based transformations** will be added later.

---

## 📌 Project Goal

- ✅ Extract data from `Credit Risk Benchmark Dataset.csv`
- ✅ Transform data using **Pandas** (cleaning, renaming, formatting)
- ✅ Load the cleaned data into a **MySQL table** using **SQLAlchemy**

---

## 🧱 Current Project Structure (ETL Only)

```bash
📂 Testingcompose/
├── data/
│   └── Credit Risk Benchmark Dataset.csv
├── etl/
│   ├── extract.py              # Read CSV using pandas
│   ├── transform.py            # Clean and transform the data
│   ├── load.py                 # Insert data into MySQL
│   └── sqlcredcheck.py         # Utility to check SQL connection
├── docker/
│   └── docker-compose.yml      # (Empty for now — to be used in next phase)
├── venv/                       # Python virtual environment
├── .env                        # Stores database credentials use like mysql_user , mysql_pass to connect it easily 
├── .gitignore
├── main.py                     # use loads.py main is still not in use since this project will soon grow and will be in realtime streaming  
├── transform.log               # Logs for transformations
├── requirements.txt            # Python dependencies
└── README.md                   # This file

data is used or taken from kaggle to use freely and for practise


🧠 Author

Khizer Nayak
Fintech & Data Engineering | Data Enthusiast
🌍 Exploring the world and data at the same time!