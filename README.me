# ğŸ§ª Mini ETL Project: Credit Risk Dataset (CSV â†’ MySQL)

This mini project demonstrates a simple and clean **ETL pipeline** that reads a credit risk CSV file,transforms it using **Pandas**, and loads it into a **MySQL database**.

This is part of a larger data engineering pipeline where **streaming (Kafka, Debezium)** and **PySpark-based transformations** will be added later.

---

## ğŸ“Œ Project Goal

- âœ… Extract data from `Credit Risk Benchmark Dataset.csv`
- âœ… Transform data using **Pandas** (cleaning, renaming, formatting)
- âœ… Load the cleaned data into a **MySQL table** using **SQLAlchemy**

---

## ğŸ§± Current Project Structure (ETL Only)

```bash
ğŸ“‚ Testingcompose/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Credit Risk Benchmark Dataset.csv
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ extract.py              # Read CSV using pandas
â”‚   â”œâ”€â”€ transform.py            # Clean and transform the data
â”‚   â”œâ”€â”€ load.py                 # Insert data into MySQL
â”‚   â””â”€â”€ sqlcredcheck.py         # Utility to check SQL connection
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ docker-compose.yml      # (Empty for now â€” to be used in next phase)
â”œâ”€â”€ venv/                       # Python virtual environment
â”œâ”€â”€ .env                        # Stores database credentials use like mysql_user , mysql_pass to connect it easily 
â”œâ”€â”€ .gitignore
â”œâ”€â”€ main.py                     # use loads.py main is still not in use since this project will soon grow and will be in realtime streaming  
â”œâ”€â”€ transform.log               # Logs for transformations
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # This file

data is used or taken from kaggle to use freely and for practise


ğŸ§  Author

Khizer Nayak
Fintech & Data Engineering | Data Enthusiast
ğŸŒ Exploring the world and data at the same time!